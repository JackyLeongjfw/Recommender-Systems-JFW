{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fffb7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAT3009 — Full TabRS.SVD Midterm Pipeline with CV & Hyperparameter Tuning\n",
    "# Requirements: numpy, pandas, sklearn\n",
    "# Make sure you have internet or that TabRS.py is available locally.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/competitions/cuhk-stat-3009-quiz-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a9dca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TabRS.py already exists — skipping download\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "user = \"statmlben\"\n",
    "repo = \"CUHK-STAT3009\"\n",
    "src = \"src\"\n",
    "pyfile = \"TabRS.py\"\n",
    "url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{src}/{pyfile}\"\n",
    "\n",
    "# Download TabRS.py if missing\n",
    "if not Path(\"TabRS.py\").exists():\n",
    "    print(\"Downloading TabRS.py from GitHub ...\")\n",
    "    urllib.request.urlretrieve(url, \"TabRS.py\")\n",
    "else:\n",
    "    print(\"✅ TabRS.py already exists — skipping download\")\n",
    "\n",
    "from TabRS import SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee70bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (80, 4)\n",
      "test shape (20, 3)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Data paths — adjust if needed\n",
    "# ---------------------------\n",
    "# DATA_DIR = Path('/kaggle/input/cuhk-stat-3009-quiz-2')  # <- change to your path if needed\n",
    "# TRAIN_CSV = DATA_DIR / 'train.csv'\n",
    "# TEST_CSV = DATA_DIR / 'test.csv'\n",
    "# SAMPLE_SUB = DATA_DIR / 'sample_submission.csv'\n",
    "\n",
    "# optional side files\n",
    "# USER_FEATS = DATA_DIR / 'user_feats.csv'\n",
    "# ITEM_FEATS = DATA_DIR / 'item_feats.csv'\n",
    "# USER_SOCIAL = DATA_DIR / 'user_social_net.csv'\n",
    "\n",
    "TRAIN_CSV = 'fake_midterm_data/train.csv'\n",
    "TEST_CSV = 'fake_midterm_data/test.csv'\n",
    "SAMPLE_SUB = 'fake_midterm_data/sample_submission.csv'\n",
    "\n",
    "# load\n",
    "train = pd.read_csv(TRAIN_CSV)\n",
    "test = pd.read_csv(TEST_CSV)\n",
    "sample_submission = pd.read_csv(SAMPLE_SUB)\n",
    "\n",
    "USER_FEATS = 'fake_midterm_data/user_feats.csv'\n",
    "ITEM_FEATS = 'fake_midterm_data/item_feats.csv'\n",
    "\n",
    "\n",
    "print('train shape', train.shape)\n",
    "print('test shape', test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3be1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users=8, n_items=10, n_groups=3\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2. Remap IDs to contiguous integers (0..n-1) for user,item,group\n",
    "# ---------------------------\n",
    "# Build unions so test unseen ids are mapped too\n",
    "all_users = np.union1d(train['userID'].unique(), test['userID'].unique())\n",
    "all_items = np.union1d(train['itemID'].unique(), test['itemID'].unique())\n",
    "all_groups = np.union1d(train['groupID'].unique(), test['groupID'].unique())\n",
    "\n",
    "user2idx = {u:i for i,u in enumerate(all_users)}\n",
    "item2idx = {it:i for i,it in enumerate(all_items)}\n",
    "group2idx = {g:i for i,g in enumerate(all_groups)}\n",
    "\n",
    "# remap train/test (new columns: u_idx, i_idx, g_idx)\n",
    "train = train.copy()\n",
    "test = test.copy()\n",
    "train['u_idx'] = train['userID'].map(user2idx).astype(int)\n",
    "train['i_idx'] = train['itemID'].map(item2idx).astype(int)\n",
    "train['g_idx'] = train['groupID'].map(group2idx).astype(int)\n",
    "\n",
    "test['u_idx'] = test['userID'].map(user2idx).astype(int)\n",
    "test['i_idx'] = test['itemID'].map(item2idx).astype(int)\n",
    "test['g_idx'] = test['groupID'].map(group2idx).astype(int)\n",
    "\n",
    "n_users = len(user2idx)\n",
    "n_items = len(item2idx)\n",
    "n_groups = len(group2idx)\n",
    "print(f\"n_users={n_users}, n_items={n_items}, n_groups={n_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8375f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. CV + Grid search helpers (works with TabRS.SVD)\n",
    "# ---------------------------\n",
    "def cv_score_svd(X_pairs, y, n_rows, n_cols, params, n_splits=3, random_state=42, verbose=False):\n",
    "    \"\"\"\n",
    "    X_pairs: np.array shape (n_samples,2) containing [left_id, right_id] (already remapped)\n",
    "    n_rows, n_cols: sizes for SVD constructor (order: first arg, second arg)\n",
    "    params: dict with keys 'K','lam','iterNum'\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "    for tr_idx, val_idx in kf.split(X_pairs):\n",
    "        X_tr, X_val = X_pairs[tr_idx], X_pairs[val_idx]\n",
    "        y_tr, y_val = y[tr_idx], y[val_idx]\n",
    "\n",
    "        # instantiate SVD — TabRS.SVD signature: SVD(n_users, n_items, lam=.001, K=10, iterNum=10, tol=..., verbose=...)\n",
    "        model = SVD(n_rows, n_cols, lam=params['lam'], K=params['K'], iterNum=params['iterNum'], tol=params.get('tol',1e-4), verbose=0)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        preds = model.predict(X_val)\n",
    "        scores.append(rmse(y_val, preds))\n",
    "    mean_score = float(np.mean(scores))\n",
    "    std_score = float(np.std(scores))\n",
    "    if verbose:\n",
    "        print(f\"params {params} -> CV RMSE = {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    return mean_score, std_score\n",
    "\n",
    "def grid_search_svd(X_pairs, y, n_rows, n_cols, param_grid, n_splits=3, random_state=42, verbose=True):\n",
    "    combos = [dict(zip(param_grid.keys(), vals)) for vals in itertools.product(*param_grid.values())]\n",
    "    best_score = 1e9\n",
    "    best_params = None\n",
    "    results = []\n",
    "    start = time.time()\n",
    "    for p in combos:\n",
    "        mean_rmse, std_rmse = cv_score_svd(X_pairs, y, n_rows, n_cols, p, n_splits=n_splits, random_state=random_state, verbose=False)\n",
    "        results.append((p, mean_rmse, std_rmse))\n",
    "        if verbose:\n",
    "            print(f\"params {p} -> RMSE {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "        if mean_rmse < best_score:\n",
    "            best_score = mean_rmse\n",
    "            best_params = p\n",
    "    elapsed = time.time() - start\n",
    "    if verbose:\n",
    "        print(f\"Grid search finished in {elapsed:.1f}s. Best: {best_params} RMSE={best_score:.4f}\")\n",
    "    return best_params, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "782b45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4. Parameter grid (keep reasonably small; expand if you have time)\n",
    "# ---------------------------\n",
    "param_grid = {\n",
    "    'K': [5, 10, 20],\n",
    "    'lam': [0.001, 0.01, 0.1],\n",
    "    'iterNum': [5, 10]  # avoid huge iterNums for CV runtime\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a04c699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grid search: SVD (user + item) ===\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.6848 ± 0.1542\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.5130 ± 0.0408\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.4477 ± 0.0821\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.5647 ± 0.1622\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.2384 ± 0.0322\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2378 ± 0.0310\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.9236 ± 0.0924\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.6268 ± 0.0518\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.5913 ± 0.1067\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.3780 ± 0.1066\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.2399 ± 0.0299\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2379 ± 0.0307\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 5} -> RMSE 2.0495 ± 0.3042\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.7965 ± 0.3089\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.4225 ± 0.1832\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.5867 ± 0.1476\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.3150 ± 0.0877\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2379 ± 0.0310\n",
      "Grid search finished in 1.1s. Best: {'K': 5, 'lam': 0.1, 'iterNum': 10} RMSE=1.2378\n",
      "\n",
      "=== Grid search: SVD (user + group) ===\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.2215 ± 0.0488\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.2122 ± 0.0446\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.1885 ± 0.0377\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.2201 ± 0.0642\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.1658 ± 0.0384\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.1667 ± 0.0387\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.2074 ± 0.0403\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.3685 ± 0.2441\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.2246 ± 0.0641\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.2074 ± 0.0432\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.1671 ± 0.0364\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.1842 ± 0.0306\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.2310 ± 0.0599\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.2267 ± 0.0504\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.1664 ± 0.0313\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.2661 ± 0.1323\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.1604 ± 0.0418\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.1666 ± 0.0387\n",
      "Grid search finished in 0.7s. Best: {'K': 20, 'lam': 0.1, 'iterNum': 5} RMSE=1.1604\n",
      "\n",
      "=== Grid search: SVD (item + group) ===\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.3842 ± 0.0546\n",
      "params {'K': 5, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.3723 ± 0.0574\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.3322 ± 0.0761\n",
      "params {'K': 5, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.3278 ± 0.0578\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.2591 ± 0.0356\n",
      "params {'K': 5, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2607 ± 0.0359\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.3866 ± 0.0319\n",
      "params {'K': 10, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.3533 ± 0.0575\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.2982 ± 0.0697\n",
      "params {'K': 10, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.2881 ± 0.0461\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.2591 ± 0.0357\n",
      "params {'K': 10, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2606 ± 0.0358\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 5} -> RMSE 1.3386 ± 0.0255\n",
      "params {'K': 20, 'lam': 0.001, 'iterNum': 10} -> RMSE 1.4007 ± 0.0964\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 5} -> RMSE 1.3551 ± 0.0448\n",
      "params {'K': 20, 'lam': 0.01, 'iterNum': 10} -> RMSE 1.3188 ± 0.0291\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 5} -> RMSE 1.2523 ± 0.0266\n",
      "params {'K': 20, 'lam': 0.1, 'iterNum': 10} -> RMSE 1.2601 ± 0.0359\n",
      "Grid search finished in 0.9s. Best: {'K': 20, 'lam': 0.1, 'iterNum': 5} RMSE=1.2523\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 5. CV + Grid search for each variant\n",
    "#    a) user + item\n",
    "# ---------------------------\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "pairs_ui = np.vstack([train['u_idx'].values, train['i_idx'].values]).T\n",
    "y = train['rating'].values\n",
    "print(\"\\n=== Grid search: SVD (user + item) ===\")\n",
    "best_ui_params, ui_results = grid_search_svd(pairs_ui, y, n_users, n_items, param_grid, n_splits=3)\n",
    "\n",
    "# ---------------------------\n",
    "#    b) user + group\n",
    "# ---------------------------\n",
    "pairs_ug = np.vstack([train['u_idx'].values, train['g_idx'].values]).T\n",
    "print(\"\\n=== Grid search: SVD (user + group) ===\")\n",
    "best_ug_params, ug_results = grid_search_svd(pairs_ug, y, n_users, n_groups, param_grid, n_splits=3)\n",
    "\n",
    "# ---------------------------\n",
    "#    c) item + group\n",
    "# ---------------------------\n",
    "pairs_ig = np.vstack([train['i_idx'].values, train['g_idx'].values]).T\n",
    "print(\"\\n=== Grid search: SVD (item + group) ===\")\n",
    "best_ig_params, ig_results = grid_search_svd(pairs_ig, y, n_items, n_groups, param_grid, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29aa3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training final models on full train data ===\n",
      "Training SVD(user+item) with {'K': 5, 'lam': 0.1, 'iterNum': 10}\n",
      "Fitting Reg-SVD: K: 5, lam: 0.10000\n",
      "RegSVD-ALS: 0; obj: 1.458; rmse:1.113, diff: 20.591\n",
      "RegSVD-ALS: 1; obj: 0.973; rmse:0.979, diff: 0.485\n",
      "RegSVD-ALS: 2; obj: 0.953; rmse:0.975, diff: 0.020\n",
      "RegSVD-ALS: 3; obj: 0.951; rmse:0.975, diff: 0.001\n",
      "RegSVD-ALS: 4; obj: 0.951; rmse:0.975, diff: 0.000\n",
      "RegSVD-ALS: 5; obj: 0.951; rmse:0.975, diff: 0.000\n",
      "Training SVD(user+group) with {'K': 20, 'lam': 0.1, 'iterNum': 5}\n",
      "Fitting Reg-SVD: K: 20, lam: 0.10000\n",
      "RegSVD-ALS: 0; obj: 2.666; rmse:1.172, diff: 72.435\n",
      "RegSVD-ALS: 1; obj: 1.928; rmse:1.102, diff: 0.738\n",
      "RegSVD-ALS: 2; obj: 1.437; rmse:1.051, diff: 0.491\n",
      "RegSVD-ALS: 3; obj: 1.174; rmse:1.019, diff: 0.263\n",
      "RegSVD-ALS: 4; obj: 1.100; rmse:1.012, diff: 0.074\n",
      "Training SVD(item+group) with {'K': 20, 'lam': 0.1, 'iterNum': 5}\n",
      "Fitting Reg-SVD: K: 20, lam: 0.10000\n",
      "RegSVD-ALS: 0; obj: 2.784; rmse:1.342, diff: 61.687\n",
      "RegSVD-ALS: 1; obj: 1.497; rmse:1.108, diff: 1.287\n",
      "RegSVD-ALS: 2; obj: 1.140; rmse:1.049, diff: 0.358\n",
      "RegSVD-ALS: 3; obj: 1.110; rmse:1.049, diff: 0.030\n",
      "RegSVD-ALS: 4; obj: 1.108; rmse:1.051, diff: 0.001\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6. Train final models on full train set using best params\n",
    "# ---------------------------\n",
    "print(\"\\n=== Training final models on full train data ===\")\n",
    "\n",
    "# user+item final\n",
    "print(\"Training SVD(user+item) with\", best_ui_params)\n",
    "svd_ui = SVD(n_users, n_items,\n",
    "             lam=best_ui_params['lam'], K=best_ui_params['K'], iterNum=best_ui_params['iterNum'], verbose=1)\n",
    "svd_ui.fit(pairs_ui, y)\n",
    "test_pairs_ui = np.vstack([test['u_idx'].values, test['i_idx'].values]).T\n",
    "pred_ui = svd_ui.predict(test_pairs_ui)\n",
    "\n",
    "# user+group final\n",
    "print(\"Training SVD(user+group) with\", best_ug_params)\n",
    "svd_ug = SVD(n_users, n_groups,\n",
    "             lam=best_ug_params['lam'], K=best_ug_params['K'], iterNum=best_ug_params['iterNum'], verbose=1)\n",
    "svd_ug.fit(pairs_ug, y)\n",
    "test_pairs_ug = np.vstack([test['u_idx'].values, test['g_idx'].values]).T\n",
    "pred_ug = svd_ug.predict(test_pairs_ug)\n",
    "\n",
    "# item+group final\n",
    "print(\"Training SVD(item+group) with\", best_ig_params)\n",
    "svd_ig = SVD(n_items, n_groups,\n",
    "             lam=best_ig_params['lam'], K=best_ig_params['K'], iterNum=best_ig_params['iterNum'], verbose=1)\n",
    "svd_ig.fit(pairs_ig, y)\n",
    "test_pairs_ig = np.vstack([test['i_idx'].values, test['g_idx'].values]).T\n",
    "pred_ig = svd_ig.predict(test_pairs_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f90e8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7. Ensemble averaging & save\n",
    "# ---------------------------\n",
    "pred_ensemble = (pred_ui + pred_ug + pred_ig) / 3.0\n",
    "submission = sample_submission.copy()\n",
    "submission['rating'] = pred_ensemble\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16947d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>groupID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userID  itemID  groupID  rating\n",
       "0        6       6        2    3.91\n",
       "1        3       7        2    2.47\n",
       "2        4       2        0    3.53\n",
       "3        6       0        2    3.53\n",
       "4        2       3        2    3.14\n",
       "..     ...     ...      ...     ...\n",
       "75       1       6        2    1.78\n",
       "76       3       0        2    3.89\n",
       "77       3       3        2    2.12\n",
       "78       6       3        2    1.10\n",
       "79       3       4        0    3.58\n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f9a8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode userID and itemID to contiguous integer indices\n",
    "train['u_idx'] = train['userID'].astype('category').cat.codes\n",
    "train['i_idx'] = train['itemID'].astype('category').cat.codes\n",
    "test['u_idx'] = test['userID'].astype('category').cat.codes\n",
    "test['i_idx'] = test['itemID'].astype('category').cat.codes\n",
    "\n",
    "# Also group if needed\n",
    "train['g_idx'] = train['groupID'].astype('category').cat.codes\n",
    "test['g_idx'] = test['groupID'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "defa2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Enhanced Hybrid + Fallback Ensemble ===\n",
      "✅ Saved submission_tabrs_final_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Enhanced Hybrid + Fallback Ensemble ===\")\n",
    "\n",
    "# 1️⃣ Collect base SVD predictions (aligned with test.csv order)\n",
    "pred_ensemble = (pred_ui + pred_ug + pred_ig) / 3.0\n",
    "\n",
    "# 2️⃣ Cold-start fallback for missing user/item pairs\n",
    "item_mean = train.groupby('i_idx')['rating'].mean().to_dict()\n",
    "global_mean = train['rating'].mean()\n",
    "known_users_idx = set(train['u_idx'].unique())\n",
    "known_items_idx = set(train['i_idx'].unique())\n",
    "\n",
    "def predict_with_fallback_idx(u_idx, i_idx, model, default_pred):\n",
    "    # if both known -> ensemble prediction\n",
    "    if (u_idx in known_users_idx) and (i_idx in known_items_idx):\n",
    "        return default_pred\n",
    "    # if item known -> item mean\n",
    "    if i_idx in item_mean:\n",
    "        return item_mean[i_idx]\n",
    "    # else global\n",
    "    return global_mean\n",
    "\n",
    "preds_combined = np.array([\n",
    "    predict_with_fallback_idx(u, i, svd_ui, p)\n",
    "    for u, i, p in zip(test['u_idx'], test['i_idx'], pred_ensemble)\n",
    "])\n",
    "\n",
    "# 3️⃣ Build hybrid dataset (add features)\n",
    "user_feats = pd.read_csv(USER_FEATS)\n",
    "item_feats = pd.read_csv(ITEM_FEATS)\n",
    "\n",
    "# --- Prepare training data ---\n",
    "df = train[['userID', 'itemID', 'u_idx', 'i_idx', 'rating']].copy()\n",
    "# Add ensemble predictions (average of 3 SVDs)\n",
    "df['svd_ui'] = svd_ui.predict(df[['u_idx','i_idx']].values)\n",
    "df['svd_ug'] = svd_ug.predict(np.vstack([df['u_idx'], train['g_idx']]).T)\n",
    "df['svd_ig'] = svd_ig.predict(np.vstack([df['i_idx'], train['g_idx']]).T)\n",
    "df['svd_ensemble'] = (df['svd_ui'] + df['svd_ug'] + df['svd_ig']) / 3.0\n",
    "\n",
    "# Merge user and item features\n",
    "df = df.merge(user_feats, on='userID', how='left')\n",
    "df = df.merge(item_feats, on='itemID', how='left')\n",
    "\n",
    "# --- Encode + clean ---\n",
    "for c in df.columns:\n",
    "    if df[c].dtype.kind in 'biufc':\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "    else:\n",
    "        df[c] = df[c].fillna('NA')\n",
    "\n",
    "ignore_cols = {'userID', 'itemID', 'u_idx', 'i_idx', 'rating'}\n",
    "cat_cols = [c for c in df.columns if c not in ignore_cols and df[c].dtype == object]\n",
    "df = pd.get_dummies(df, columns=cat_cols, dummy_na=True)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ignore_cols]\n",
    "X = df[feature_cols].values\n",
    "y = df['rating'].values\n",
    "\n",
    "# 4️⃣ Train Ridge on all features\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "# --- Prepare test data ---\n",
    "test_df = test[['userID','itemID','u_idx','i_idx','groupID']].copy()\n",
    "test_df['svd_ui'] = pred_ui\n",
    "test_df['svd_ug'] = pred_ug\n",
    "test_df['svd_ig'] = pred_ig\n",
    "test_df['svd_ensemble'] = preds_combined  # includes fallback logic\n",
    "\n",
    "test_df = test_df.merge(user_feats, on='userID', how='left')\n",
    "test_df = test_df.merge(item_feats, on='itemID', how='left')\n",
    "\n",
    "for c in test_df.columns:\n",
    "    if test_df[c].dtype.kind in 'biufc':\n",
    "        test_df[c] = test_df[c].fillna(df[c].mean() if c in df.columns else 0)\n",
    "    else:\n",
    "        test_df[c] = test_df[c].fillna('NA')\n",
    "\n",
    "test_df = pd.get_dummies(test_df, columns=[c for c in cat_cols if c in test_df.columns], dummy_na=True)\n",
    "for c in feature_cols:\n",
    "    if c not in test_df.columns:\n",
    "        test_df[c] = 0\n",
    "X_test = test_df[feature_cols].values\n",
    "\n",
    "# 5️⃣ Final prediction (hybrid + ensemble + fallback)\n",
    "pred_final = ridge.predict(X_test)\n",
    "pred_final = np.clip(pred_final, train['rating'].min(), train['rating'].max())\n",
    "\n",
    "# Save final submission\n",
    "submission_final = sample_submission.copy()\n",
    "submission_final['rating'] = pred_final\n",
    "submission_final.to_csv('submission_tabrs_final_ensemble.csv', index=False)\n",
    "print(\"✅ Saved submission_tabrs_final_ensemble.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['age', 'income'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 10. Social graph smoothing / blending (if available)\n",
    "# ---------------------------\n",
    "if USER_SOCIAL.exists():\n",
    "    print(\"\\n=== Social graph blending ===\")\n",
    "    edges = pd.read_csv(USER_SOCIAL)\n",
    "    # expect columns like ['from','to'] in original IDs; we map them to idx if possible\n",
    "    # try to detect column names\n",
    "    if 'from' in edges.columns and 'to' in edges.columns:\n",
    "        col_from, col_to = 'from', 'to'\n",
    "    elif 'follower' in edges.columns and 'followee' in edges.columns:\n",
    "        col_from, col_to = 'follower', 'followee'\n",
    "    else:\n",
    "        # try first two columns\n",
    "        col_from, col_to = edges.columns[0], edges.columns[1]\n",
    "\n",
    "    # map original ids -> idx if exist in mapping; otherwise ignore those edges\n",
    "    def map_if_present(x, mapping):\n",
    "        return mapping[x] if x in mapping else None\n",
    "\n",
    "    followees = {}\n",
    "    for _, row in edges.iterrows():\n",
    "        a = row[col_from]\n",
    "        b = row[col_to]\n",
    "        if (a in user2idx) and (b in user2idx):\n",
    "            ai = user2idx[a]; bi = user2idx[b]\n",
    "            followees.setdefault(ai, []).append(bi)\n",
    "\n",
    "    # user mean ratings (by idx)\n",
    "    user_mean_idx = train.groupby('u_idx')['rating'].mean().to_dict()\n",
    "\n",
    "    social_preds = []\n",
    "    for u_orig, i_orig in zip(test['userID'], test['itemID']):\n",
    "        u_idx = user2idx.get(u_orig, None)\n",
    "        i_idx = item2idx.get(i_orig, None)\n",
    "        if u_idx is None or i_idx is None:\n",
    "            social_preds.append(np.nan); continue\n",
    "        friends = followees.get(u_idx, [])\n",
    "        vals = [user_mean_idx.get(f, np.nan) for f in friends if f in user_mean_idx]\n",
    "        vals = [v for v in vals if not np.isnan(v)]\n",
    "        if len(vals) > 0:\n",
    "            social_preds.append(np.mean(vals))\n",
    "        else:\n",
    "            social_preds.append(np.nan)\n",
    "    social_preds = np.array(social_preds)\n",
    "\n",
    "    # blend: where social exists, blend 80% ensemble + 20% social average\n",
    "    blended = np.where(~np.isnan(social_preds), 0.8 * pred_ensemble + 0.2 * social_preds, pred_ensemble)\n",
    "    submission_social = sample_submission.copy()\n",
    "    submission_social['rating'] = blended\n",
    "    social_path = out_dir / 'submission_tabrs_social.csv'\n",
    "    submission_social.to_csv(social_path, index=False)\n",
    "    print(f\"Saved social blend submission: {social_path}\")\n",
    "else:\n",
    "    print(\"\\nNo user_social_net found — skipping social blending.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 11. Summary printout\n",
    "# ---------------------------\n",
    "print(\"\\n=== Done ===\\nGenerated files in:\", out_dir)\n",
    "print(\"- ensemble:\", ensemble_path)\n",
    "if 'hybrid_path' in locals():\n",
    "    print(\"- hybrid:\", hybrid_path)\n",
    "print(\"- fallback:\", fallback_path)\n",
    "if 'social_path' in locals():\n",
    "    print(\"- social blend:\", social_path)\n",
    "\n",
    "# Optionally save CV results as CSV for inspection\n",
    "cv_out = out_dir / 'cv_results_summary.csv'\n",
    "rows = []\n",
    "for p,mean,std in ui_results:\n",
    "    rows.append({'model':'user_item', 'K':p['K'], 'lam':p['lam'], 'iterNum':p['iterNum'], 'rmse':mean, 'std':std})\n",
    "for p,mean,std in ug_results:\n",
    "    rows.append({'model':'user_group', 'K':p['K'], 'lam':p['lam'], 'iterNum':p['iterNum'], 'rmse':mean, 'std':std})\n",
    "for p,mean,std in ig_results:\n",
    "    rows.append({'model':'item_group', 'K':p['K'], 'lam':p['lam'], 'iterNum':p['iterNum'], 'rmse':mean, 'std':std})\n",
    "pd.DataFrame(rows).to_csv(cv_out, index=False)\n",
    "print(\"Saved CV summary:\", cv_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
